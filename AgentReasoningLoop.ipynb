{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import openai\n",
    "import nest_asyncio\n",
    "nest_asyncio.apply()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "openai.api_key = 'Your API KEY'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setting Up the Query Tools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils import get_doc_tools\n",
    "\n",
    "vector_tool, summary_tool = get_doc_tools('metagpt.pdf', 'metagpt')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## setup Function Calling Agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.llms.openai import OpenAI\n",
    "\n",
    "llm = OpenAI(model='gpt-3.5-turbo', temperature=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.core.agent import FunctionCallingAgentWorker\n",
    "from llama_index.core.agent import AgentRunner\n",
    "\n",
    "agent_worker = FunctionCallingAgentWorker.from_tools(\n",
    "    [vector_tool, summary_tool],\n",
    "    llm=llm,\n",
    "    verbose=True\n",
    ")\n",
    "\n",
    "agent = AgentRunner(agent_worker)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Added user message to memory: Tell me about the agent roles in MetaGPT,and then how they communicate with each other.\n",
      "=== Calling Function ===\n",
      "Calling function: summary_tool_metagpt with args: {\"input\": \"agent roles in MetaGPT\"}\n",
      "=== Function Output ===\n",
      "The roles in MetaGPT include the Product Manager responsible for creating the Product Requirement Document and competitive analysis, the Architect who designs system architecture and technical specifications, the Project Manager who breaks down tasks and manages the task list, the Engineer who implements code based on specifications, and the QA Engineer who generates unit tests and ensures software quality. Each agent's specialized role contributes to the collaborative software development process in MetaGPT.\n",
      "=== Calling Function ===\n",
      "Calling function: summary_tool_metagpt with args: {\"input\": \"how agents communicate with each other in MetaGPT\"}\n",
      "=== Function Output ===\n",
      "Agents in MetaGPT communicate with each other through structured communication interfaces, a publish-subscribe mechanism, a shared message pool, and role profiles. This approach allows them to exchange information directly, access relevant messages, and filter out distractions, ensuring they receive only task-related information. This structured communication system enhances efficiency, streamlines workflows, and improves collaboration among the agents in MetaGPT.\n",
      "=== LLM Response ===\n",
      "In MetaGPT, the agent roles include the Product Manager, Architect, Project Manager, Engineer, and QA Engineer. Each agent has a specialized role contributing to the collaborative software development process. \n",
      "\n",
      "Agents in MetaGPT communicate with each other through structured communication interfaces, a publish-subscribe mechanism, a shared message pool, and role profiles. This approach enables them to exchange information directly, access relevant messages, and filter out distractions, ensuring they receive only task-related information. This structured communication system enhances efficiency, streamlines workflows, and improves collaboration among the agents in MetaGPT.\n"
     ]
    }
   ],
   "source": [
    "response = agent.query(\n",
    "    \"Tell me about the agent roles in MetaGPT,\"\n",
    "    \"and then how they communicate with each other.\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Added user message to memory: Tell me about the evaluation datasets used.\n",
      "=== Calling Function ===\n",
      "Calling function: summary_tool_metagpt with args: {\"input\": \"evaluation datasets used in MetaGPT\"}\n",
      "=== Function Output ===\n",
      "The evaluation datasets used in MetaGPT include HumanEval, MBPP, and a self-generated SoftwareDev dataset.\n",
      "=== LLM Response ===\n",
      "The evaluation datasets used in MetaGPT include HumanEval, MBPP, and a self-generated SoftwareDev dataset.\n"
     ]
    }
   ],
   "source": [
    "response = agent.chat(\n",
    "    \"Tell me about the evaluation datasets used.\"\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
